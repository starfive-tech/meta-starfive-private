From eff753f5734bebb607696079ff7865cd292db7f7 Mon Sep 17 00:00:00 2001
From: Craig Topper <craig.topper@sifive.com>
Date: Wed, 26 Jul 2023 09:47:50 -0700
Subject: [PATCH 1/8] Handle seteq/setne conditions for CZERO_NEZ/CZERO_EQZ
 during isel.

This removes selectSETCC and adds isel patterns for seteq/setne
conditions.

This removes the duplication of selectSETCC between lowering and
isel. This also gets some cases in xaluo.ll that we missed previously.

Reviewed By: wangpc

Differential Revision: https://reviews.llvm.org/D156250
---
 llvm/lib/Target/RISCV/RISCVISelLowering.cpp   |  79 --------
 .../Target/RISCV/RISCVInstrInfoXVentana.td    |   9 +
 llvm/lib/Target/RISCV/RISCVInstrInfoZicond.td |   9 +
 llvm/test/CodeGen/RISCV/condops.ll            | 170 +++++++++---------
 llvm/test/CodeGen/RISCV/xaluo.ll              |  24 ++-
 5 files changed, 113 insertions(+), 178 deletions(-)

diff --git a/llvm/lib/Target/RISCV/RISCVISelLowering.cpp b/llvm/lib/Target/RISCV/RISCVISelLowering.cpp
index f030982cb815..9f702873c9aa 100644
--- a/llvm/lib/Target/RISCV/RISCVISelLowering.cpp
+++ b/llvm/lib/Target/RISCV/RISCVISelLowering.cpp
@@ -5904,56 +5904,6 @@ static SDValue combineSelectToBinOp(SDNode *N, SelectionDAG &DAG,
   return SDValue();
 }
 
-/// RISC-V doesn't have general instructions for integer setne/seteq, but we can
-/// check for equality with 0. This function emits nodes that convert the
-/// seteq/setne into something that can be compared with 0.
-/// Based on RISCVDAGToDAGISel::selectSETCC but modified to produce
-/// target-independent SelectionDAG nodes rather than machine nodes.
-static SDValue selectSETCC(SDValue N, ISD::CondCode ExpectedCCVal,
-                           SelectionDAG &DAG) {
-  assert(ISD::isIntEqualitySetCC(ExpectedCCVal) &&
-         "Unexpected condition code!");
-
-  // We're looking for a setcc.
-  if (N->getOpcode() != ISD::SETCC)
-    return SDValue();
-
-  // Must be an equality comparison.
-  ISD::CondCode CCVal = cast<CondCodeSDNode>(N->getOperand(2))->get();
-  if (CCVal != ExpectedCCVal)
-    return SDValue();
-
-  SDValue LHS = N->getOperand(0);
-  SDValue RHS = N->getOperand(1);
-
-  if (!LHS.getValueType().isScalarInteger())
-    return SDValue();
-
-  // If the RHS side is 0, we don't need any extra instructions, return the LHS.
-  if (isNullConstant(RHS))
-    return LHS;
-
-  SDLoc DL(N);
-
-  if (auto *C = dyn_cast<ConstantSDNode>(RHS)) {
-    int64_t CVal = C->getSExtValue();
-    // If the RHS is -2048, we can use xori to produce 0 if the LHS is -2048 and
-    // non-zero otherwise.
-    if (CVal == -2048)
-      return DAG.getNode(ISD::XOR, DL, N->getValueType(0), LHS,
-                         DAG.getConstant(CVal, DL, N->getValueType(0)));
-    // If the RHS is [-2047,2048], we can use addi with -RHS to produce 0 if the
-    // LHS is equal to the RHS and non-zero otherwise.
-    if (isInt<12>(CVal) || CVal == 2048)
-      return DAG.getNode(ISD::ADD, DL, N->getValueType(0), LHS,
-                         DAG.getConstant(-CVal, DL, N->getValueType(0)));
-  }
-
-  // If nothing else we can XOR the LHS and RHS to produce zero if they are
-  // equal and a non-zero value if they aren't.
-  return DAG.getNode(ISD::XOR, DL, N->getValueType(0), LHS, RHS);
-}
-
 // Transform `binOp (select cond, x, c0), c1` where `c0` and `c1` are constants
 // into `select cond, binOp(x, c1), binOp(c0, c1)` if profitable.
 // For now we only consider transformation profitable if `binOp(c0, c1)` ends up
@@ -6041,35 +5991,6 @@ SDValue RISCVTargetLowering::lowerSELECT(SDValue Op, SelectionDAG &DAG) const {
   // sequence or RISCVISD::SELECT_CC node (branch-based select).
   if ((Subtarget.hasStdExtZicond() || Subtarget.hasVendorXVentanaCondOps()) &&
       VT.isScalarInteger()) {
-    if (SDValue NewCondV = selectSETCC(CondV, ISD::SETNE, DAG)) {
-      // (select (riscv_setne c), t, 0) -> (czero_eqz t, c)
-      if (isNullConstant(FalseV))
-        return DAG.getNode(RISCVISD::CZERO_EQZ, DL, VT, TrueV, NewCondV);
-      // (select (riscv_setne c), 0, f) -> (czero_nez f, c)
-      if (isNullConstant(TrueV))
-        return DAG.getNode(RISCVISD::CZERO_NEZ, DL, VT, FalseV, NewCondV);
-      // (select (riscv_setne c), t, f) -> (or (czero_eqz t, c), (czero_nez f,
-      // c)
-      return DAG.getNode(
-          ISD::OR, DL, VT,
-          DAG.getNode(RISCVISD::CZERO_EQZ, DL, VT, TrueV, NewCondV),
-          DAG.getNode(RISCVISD::CZERO_NEZ, DL, VT, FalseV, NewCondV));
-    }
-    if (SDValue NewCondV =  selectSETCC(CondV, ISD::SETEQ, DAG)) {
-      // (select (riscv_seteq c), t, 0) -> (czero_nez t, c)
-      if (isNullConstant(FalseV))
-        return DAG.getNode(RISCVISD::CZERO_NEZ, DL, VT, TrueV, NewCondV);
-      // (select (riscv_seteq c), 0, f) -> (czero_eqz f, c)
-      if (isNullConstant(TrueV))
-        return DAG.getNode(RISCVISD::CZERO_EQZ, DL, VT, FalseV, NewCondV);
-      // (select (riscv_seteq c), t, f) -> (or (czero_eqz f, c), (czero_nez t,
-      // c)
-      return DAG.getNode(
-          ISD::OR, DL, VT,
-          DAG.getNode(RISCVISD::CZERO_EQZ, DL, VT, FalseV, NewCondV),
-          DAG.getNode(RISCVISD::CZERO_NEZ, DL, VT, TrueV, NewCondV));
-    }
-
     // (select c, t, 0) -> (czero_eqz t, c)
     if (isNullConstant(FalseV))
       return DAG.getNode(RISCVISD::CZERO_EQZ, DL, VT, TrueV, CondV);
diff --git a/llvm/lib/Target/RISCV/RISCVInstrInfoXVentana.td b/llvm/lib/Target/RISCV/RISCVInstrInfoXVentana.td
index f6b0feaf7628..b82321f94e90 100644
--- a/llvm/lib/Target/RISCV/RISCVInstrInfoXVentana.td
+++ b/llvm/lib/Target/RISCV/RISCVInstrInfoXVentana.td
@@ -33,4 +33,13 @@ def : Pat<(XLenVT (riscv_czero_eqz GPR:$rs1, GPR:$rc)),
           (VT_MASKC GPR:$rs1, GPR:$rc)>;
 def : Pat<(XLenVT (riscv_czero_nez GPR:$rs1, GPR:$rc)),
           (VT_MASKCN GPR:$rs1, GPR:$rc)>;
+
+def : Pat<(XLenVT (riscv_czero_eqz GPR:$rs1, (riscv_setne (XLenVT GPR:$rc)))),
+          (VT_MASKC GPR:$rs1, GPR:$rc)>;
+def : Pat<(XLenVT (riscv_czero_eqz GPR:$rs1, (riscv_seteq (XLenVT GPR:$rc)))),
+          (VT_MASKCN GPR:$rs1, GPR:$rc)>;
+def : Pat<(XLenVT (riscv_czero_nez GPR:$rs1, (riscv_setne (XLenVT GPR:$rc)))),
+          (VT_MASKCN GPR:$rs1, GPR:$rc)>;
+def : Pat<(XLenVT (riscv_czero_nez GPR:$rs1, (riscv_seteq (XLenVT GPR:$rc)))),
+          (VT_MASKC GPR:$rs1, GPR:$rc)>;
 } // Predicates = [IsRV64, HasVendorXVentanaCondOps]
diff --git a/llvm/lib/Target/RISCV/RISCVInstrInfoZicond.td b/llvm/lib/Target/RISCV/RISCVInstrInfoZicond.td
index ab0b93d62af5..0790a941823b 100644
--- a/llvm/lib/Target/RISCV/RISCVInstrInfoZicond.td
+++ b/llvm/lib/Target/RISCV/RISCVInstrInfoZicond.td
@@ -40,4 +40,13 @@ def : Pat<(XLenVT (riscv_czero_eqz GPR:$rs1, GPR:$rc)),
           (CZERO_EQZ GPR:$rs1, GPR:$rc)>;
 def : Pat<(XLenVT (riscv_czero_nez GPR:$rs1, GPR:$rc)),
           (CZERO_NEZ GPR:$rs1, GPR:$rc)>;
+
+def : Pat<(XLenVT (riscv_czero_eqz GPR:$rs1, (riscv_setne (XLenVT GPR:$rc)))),
+          (CZERO_EQZ GPR:$rs1, GPR:$rc)>;
+def : Pat<(XLenVT (riscv_czero_eqz GPR:$rs1, (riscv_seteq (XLenVT GPR:$rc)))),
+          (CZERO_NEZ GPR:$rs1, GPR:$rc)>;
+def : Pat<(XLenVT (riscv_czero_nez GPR:$rs1, (riscv_setne (XLenVT GPR:$rc)))),
+          (CZERO_NEZ GPR:$rs1, GPR:$rc)>;
+def : Pat<(XLenVT (riscv_czero_nez GPR:$rs1, (riscv_seteq (XLenVT GPR:$rc)))),
+          (CZERO_EQZ GPR:$rs1, GPR:$rc)>;
 } // Predicates = [HasStdExtZicond]
diff --git a/llvm/test/CodeGen/RISCV/condops.ll b/llvm/test/CodeGen/RISCV/condops.ll
index 19018a3e461b..a1403fc1e2e7 100644
--- a/llvm/test/CodeGen/RISCV/condops.ll
+++ b/llvm/test/CodeGen/RISCV/condops.ll
@@ -1086,8 +1086,8 @@ define i64 @seteq(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV64XVENTANACONDOPS-LABEL: seteq:
 ; RV64XVENTANACONDOPS:       # %bb.0:
 ; RV64XVENTANACONDOPS-NEXT:    xor a0, a0, a1
-; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a1, a2, a0
-; RV64XVENTANACONDOPS-NEXT:    vt.maskc a0, a3, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskc a1, a3, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a0, a2, a0
 ; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a1
 ; RV64XVENTANACONDOPS-NEXT:    ret
 ;
@@ -1103,19 +1103,19 @@ define i64 @seteq(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-NEXT:    xor a1, a1, a3
 ; RV32ZICOND-NEXT:    xor a0, a0, a2
 ; RV32ZICOND-NEXT:    or a1, a0, a1
-; RV32ZICOND-NEXT:    czero.nez a0, a4, a1
-; RV32ZICOND-NEXT:    czero.eqz a2, a6, a1
+; RV32ZICOND-NEXT:    czero.eqz a0, a6, a1
+; RV32ZICOND-NEXT:    czero.nez a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a2, a5, a1
-; RV32ZICOND-NEXT:    czero.eqz a1, a7, a1
+; RV32ZICOND-NEXT:    czero.eqz a2, a7, a1
+; RV32ZICOND-NEXT:    czero.nez a1, a5, a1
 ; RV32ZICOND-NEXT:    or a1, a1, a2
 ; RV32ZICOND-NEXT:    ret
 ;
 ; RV64ZICOND-LABEL: seteq:
 ; RV64ZICOND:       # %bb.0:
 ; RV64ZICOND-NEXT:    xor a0, a0, a1
-; RV64ZICOND-NEXT:    czero.nez a1, a2, a0
-; RV64ZICOND-NEXT:    czero.eqz a0, a3, a0
+; RV64ZICOND-NEXT:    czero.eqz a1, a3, a0
+; RV64ZICOND-NEXT:    czero.nez a0, a2, a0
 ; RV64ZICOND-NEXT:    or a0, a0, a1
 ; RV64ZICOND-NEXT:    ret
   %rc = icmp eq i64 %a, %b
@@ -1233,11 +1233,11 @@ define i64 @setgt(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setgt:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    slt a1, a3, a1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a2, a0
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1306,13 +1306,13 @@ define i64 @setge(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setge:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a0, a2
-; RV32ZICOND-NEXT:    xori a0, a0, 1
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    slt a1, a1, a3
 ; RV32ZICOND-NEXT:    xori a1, a1, 1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a0, a2
+; RV32ZICOND-NEXT:    xori a0, a0, 1
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1379,11 +1379,11 @@ define i64 @setlt(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setlt:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a0, a2
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    slt a1, a1, a3
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a0, a2
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1452,13 +1452,13 @@ define i64 @setle(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setle:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a2, a0
-; RV32ZICOND-NEXT:    xori a0, a0, 1
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    slt a1, a3, a1
 ; RV32ZICOND-NEXT:    xori a1, a1, 1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a2, a0
+; RV32ZICOND-NEXT:    xori a0, a0, 1
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1525,11 +1525,11 @@ define i64 @setugt(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setugt:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    sltu a1, a3, a1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a2, a0
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1598,13 +1598,13 @@ define i64 @setuge(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setuge:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a0, a2
-; RV32ZICOND-NEXT:    xori a0, a0, 1
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    sltu a1, a1, a3
 ; RV32ZICOND-NEXT:    xori a1, a1, 1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a0, a2
+; RV32ZICOND-NEXT:    xori a0, a0, 1
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1671,11 +1671,11 @@ define i64 @setult(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setult:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a0, a2
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    sltu a1, a1, a3
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a0, a2
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1744,13 +1744,13 @@ define i64 @setule(i64 %a, i64 %b, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: setule:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xor t0, a1, a3
-; RV32ZICOND-NEXT:    sltu a0, a2, a0
-; RV32ZICOND-NEXT:    xori a0, a0, 1
-; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
 ; RV32ZICOND-NEXT:    sltu a1, a3, a1
 ; RV32ZICOND-NEXT:    xori a1, a1, 1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, t0
-; RV32ZICOND-NEXT:    or a1, a1, a0
+; RV32ZICOND-NEXT:    sltu a0, a2, a0
+; RV32ZICOND-NEXT:    xori a0, a0, 1
+; RV32ZICOND-NEXT:    czero.nez a0, a0, t0
+; RV32ZICOND-NEXT:    or a1, a0, a1
 ; RV32ZICOND-NEXT:    czero.nez a0, a6, a1
 ; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
@@ -1795,9 +1795,9 @@ define i64 @seteq_zero(i64 %a, i64 %rs1, i64 %rs2) {
 ;
 ; RV64XVENTANACONDOPS-LABEL: seteq_zero:
 ; RV64XVENTANACONDOPS:       # %bb.0:
-; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a1, a1, a0
-; RV64XVENTANACONDOPS-NEXT:    vt.maskc a0, a2, a0
-; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a1
+; RV64XVENTANACONDOPS-NEXT:    vt.maskc a2, a2, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a0, a1, a0
+; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a2
 ; RV64XVENTANACONDOPS-NEXT:    ret
 ;
 ; RV64XTHEADCONDMOV-LABEL: seteq_zero:
@@ -1809,19 +1809,19 @@ define i64 @seteq_zero(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-LABEL: seteq_zero:
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    or a1, a0, a1
-; RV32ZICOND-NEXT:    czero.nez a0, a2, a1
-; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
+; RV32ZICOND-NEXT:    czero.eqz a0, a4, a1
+; RV32ZICOND-NEXT:    czero.nez a2, a2, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a2, a3, a1
-; RV32ZICOND-NEXT:    czero.eqz a1, a5, a1
+; RV32ZICOND-NEXT:    czero.eqz a2, a5, a1
+; RV32ZICOND-NEXT:    czero.nez a1, a3, a1
 ; RV32ZICOND-NEXT:    or a1, a1, a2
 ; RV32ZICOND-NEXT:    ret
 ;
 ; RV64ZICOND-LABEL: seteq_zero:
 ; RV64ZICOND:       # %bb.0:
-; RV64ZICOND-NEXT:    czero.nez a1, a1, a0
-; RV64ZICOND-NEXT:    czero.eqz a0, a2, a0
-; RV64ZICOND-NEXT:    or a0, a0, a1
+; RV64ZICOND-NEXT:    czero.eqz a2, a2, a0
+; RV64ZICOND-NEXT:    czero.nez a0, a1, a0
+; RV64ZICOND-NEXT:    or a0, a0, a2
 ; RV64ZICOND-NEXT:    ret
   %rc = icmp eq i64 %a, 0
   %sel = select i1 %rc, i64 %rs1, i64 %rs2
@@ -1912,9 +1912,9 @@ define i64 @seteq_constant(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV64XVENTANACONDOPS-LABEL: seteq_constant:
 ; RV64XVENTANACONDOPS:       # %bb.0:
 ; RV64XVENTANACONDOPS-NEXT:    addi a0, a0, -123
-; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a1, a1, a0
-; RV64XVENTANACONDOPS-NEXT:    vt.maskc a0, a2, a0
-; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a1
+; RV64XVENTANACONDOPS-NEXT:    vt.maskc a2, a2, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a0, a1, a0
+; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a2
 ; RV64XVENTANACONDOPS-NEXT:    ret
 ;
 ; RV64XTHEADCONDMOV-LABEL: seteq_constant:
@@ -1928,20 +1928,20 @@ define i64 @seteq_constant(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND:       # %bb.0:
 ; RV32ZICOND-NEXT:    xori a0, a0, 123
 ; RV32ZICOND-NEXT:    or a1, a0, a1
-; RV32ZICOND-NEXT:    czero.nez a0, a2, a1
-; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
+; RV32ZICOND-NEXT:    czero.eqz a0, a4, a1
+; RV32ZICOND-NEXT:    czero.nez a2, a2, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a2, a3, a1
-; RV32ZICOND-NEXT:    czero.eqz a1, a5, a1
+; RV32ZICOND-NEXT:    czero.eqz a2, a5, a1
+; RV32ZICOND-NEXT:    czero.nez a1, a3, a1
 ; RV32ZICOND-NEXT:    or a1, a1, a2
 ; RV32ZICOND-NEXT:    ret
 ;
 ; RV64ZICOND-LABEL: seteq_constant:
 ; RV64ZICOND:       # %bb.0:
 ; RV64ZICOND-NEXT:    addi a0, a0, -123
-; RV64ZICOND-NEXT:    czero.nez a1, a1, a0
-; RV64ZICOND-NEXT:    czero.eqz a0, a2, a0
-; RV64ZICOND-NEXT:    or a0, a0, a1
+; RV64ZICOND-NEXT:    czero.eqz a2, a2, a0
+; RV64ZICOND-NEXT:    czero.nez a0, a1, a0
+; RV64ZICOND-NEXT:    or a0, a0, a2
 ; RV64ZICOND-NEXT:    ret
   %rc = icmp eq i64 %a, 123
   %sel = select i1 %rc, i64 %rs1, i64 %rs2
@@ -2041,9 +2041,9 @@ define i64 @seteq_2048(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV64XVENTANACONDOPS-LABEL: seteq_2048:
 ; RV64XVENTANACONDOPS:       # %bb.0:
 ; RV64XVENTANACONDOPS-NEXT:    addi a0, a0, -2048
-; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a1, a1, a0
-; RV64XVENTANACONDOPS-NEXT:    vt.maskc a0, a2, a0
-; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a1
+; RV64XVENTANACONDOPS-NEXT:    vt.maskc a2, a2, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a0, a1, a0
+; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a2
 ; RV64XVENTANACONDOPS-NEXT:    ret
 ;
 ; RV64XTHEADCONDMOV-LABEL: seteq_2048:
@@ -2059,20 +2059,20 @@ define i64 @seteq_2048(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-NEXT:    slli a6, a6, 11
 ; RV32ZICOND-NEXT:    xor a0, a0, a6
 ; RV32ZICOND-NEXT:    or a1, a0, a1
-; RV32ZICOND-NEXT:    czero.nez a0, a2, a1
-; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
+; RV32ZICOND-NEXT:    czero.eqz a0, a4, a1
+; RV32ZICOND-NEXT:    czero.nez a2, a2, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a2, a3, a1
-; RV32ZICOND-NEXT:    czero.eqz a1, a5, a1
+; RV32ZICOND-NEXT:    czero.eqz a2, a5, a1
+; RV32ZICOND-NEXT:    czero.nez a1, a3, a1
 ; RV32ZICOND-NEXT:    or a1, a1, a2
 ; RV32ZICOND-NEXT:    ret
 ;
 ; RV64ZICOND-LABEL: seteq_2048:
 ; RV64ZICOND:       # %bb.0:
 ; RV64ZICOND-NEXT:    addi a0, a0, -2048
-; RV64ZICOND-NEXT:    czero.nez a1, a1, a0
-; RV64ZICOND-NEXT:    czero.eqz a0, a2, a0
-; RV64ZICOND-NEXT:    or a0, a0, a1
+; RV64ZICOND-NEXT:    czero.eqz a2, a2, a0
+; RV64ZICOND-NEXT:    czero.nez a0, a1, a0
+; RV64ZICOND-NEXT:    or a0, a0, a2
 ; RV64ZICOND-NEXT:    ret
   %rc = icmp eq i64 %a, 2048
   %sel = select i1 %rc, i64 %rs1, i64 %rs2
@@ -2107,9 +2107,9 @@ define i64 @seteq_neg2048(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV64XVENTANACONDOPS-LABEL: seteq_neg2048:
 ; RV64XVENTANACONDOPS:       # %bb.0:
 ; RV64XVENTANACONDOPS-NEXT:    xori a0, a0, -2048
-; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a1, a1, a0
-; RV64XVENTANACONDOPS-NEXT:    vt.maskc a0, a2, a0
-; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a1
+; RV64XVENTANACONDOPS-NEXT:    vt.maskc a2, a2, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a0, a1, a0
+; RV64XVENTANACONDOPS-NEXT:    or a0, a0, a2
 ; RV64XVENTANACONDOPS-NEXT:    ret
 ;
 ; RV64XTHEADCONDMOV-LABEL: seteq_neg2048:
@@ -2124,20 +2124,20 @@ define i64 @seteq_neg2048(i64 %a, i64 %rs1, i64 %rs2) {
 ; RV32ZICOND-NEXT:    not a1, a1
 ; RV32ZICOND-NEXT:    xori a0, a0, -2048
 ; RV32ZICOND-NEXT:    or a1, a0, a1
-; RV32ZICOND-NEXT:    czero.nez a0, a2, a1
-; RV32ZICOND-NEXT:    czero.eqz a2, a4, a1
+; RV32ZICOND-NEXT:    czero.eqz a0, a4, a1
+; RV32ZICOND-NEXT:    czero.nez a2, a2, a1
 ; RV32ZICOND-NEXT:    or a0, a2, a0
-; RV32ZICOND-NEXT:    czero.nez a2, a3, a1
-; RV32ZICOND-NEXT:    czero.eqz a1, a5, a1
+; RV32ZICOND-NEXT:    czero.eqz a2, a5, a1
+; RV32ZICOND-NEXT:    czero.nez a1, a3, a1
 ; RV32ZICOND-NEXT:    or a1, a1, a2
 ; RV32ZICOND-NEXT:    ret
 ;
 ; RV64ZICOND-LABEL: seteq_neg2048:
 ; RV64ZICOND:       # %bb.0:
 ; RV64ZICOND-NEXT:    xori a0, a0, -2048
-; RV64ZICOND-NEXT:    czero.nez a1, a1, a0
-; RV64ZICOND-NEXT:    czero.eqz a0, a2, a0
-; RV64ZICOND-NEXT:    or a0, a0, a1
+; RV64ZICOND-NEXT:    czero.eqz a2, a2, a0
+; RV64ZICOND-NEXT:    czero.nez a0, a1, a0
+; RV64ZICOND-NEXT:    or a0, a0, a2
 ; RV64ZICOND-NEXT:    ret
   %rc = icmp eq i64 %a, -2048
   %sel = select i1 %rc, i64 %rs1, i64 %rs2
@@ -3466,9 +3466,9 @@ define signext i16 @numsignbits(i16 signext %0, i16 signext %1, i16 signext %2,
 ; RV64XVENTANACONDOPS-NEXT:    addi sp, sp, -16
 ; RV64XVENTANACONDOPS-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
 ; RV64XVENTANACONDOPS-NEXT:    sd s0, 0(sp) # 8-byte Folded Spill
-; RV64XVENTANACONDOPS-NEXT:    vt.maskcn a3, a3, a0
-; RV64XVENTANACONDOPS-NEXT:    vt.maskc s0, a2, a0
-; RV64XVENTANACONDOPS-NEXT:    or s0, s0, a3
+; RV64XVENTANACONDOPS-NEXT:    vt.maskc a2, a2, a0
+; RV64XVENTANACONDOPS-NEXT:    vt.maskcn s0, a3, a0
+; RV64XVENTANACONDOPS-NEXT:    or s0, s0, a2
 ; RV64XVENTANACONDOPS-NEXT:    beqz a1, .LBB58_2
 ; RV64XVENTANACONDOPS-NEXT:  # %bb.1:
 ; RV64XVENTANACONDOPS-NEXT:    mv a0, s0
@@ -3503,9 +3503,9 @@ define signext i16 @numsignbits(i16 signext %0, i16 signext %1, i16 signext %2,
 ; RV32ZICOND-NEXT:    addi sp, sp, -16
 ; RV32ZICOND-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
 ; RV32ZICOND-NEXT:    sw s0, 8(sp) # 4-byte Folded Spill
-; RV32ZICOND-NEXT:    czero.nez a3, a3, a0
-; RV32ZICOND-NEXT:    czero.eqz s0, a2, a0
-; RV32ZICOND-NEXT:    or s0, s0, a3
+; RV32ZICOND-NEXT:    czero.eqz a2, a2, a0
+; RV32ZICOND-NEXT:    czero.nez s0, a3, a0
+; RV32ZICOND-NEXT:    or s0, s0, a2
 ; RV32ZICOND-NEXT:    beqz a1, .LBB58_2
 ; RV32ZICOND-NEXT:  # %bb.1:
 ; RV32ZICOND-NEXT:    mv a0, s0
@@ -3522,9 +3522,9 @@ define signext i16 @numsignbits(i16 signext %0, i16 signext %1, i16 signext %2,
 ; RV64ZICOND-NEXT:    addi sp, sp, -16
 ; RV64ZICOND-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
 ; RV64ZICOND-NEXT:    sd s0, 0(sp) # 8-byte Folded Spill
-; RV64ZICOND-NEXT:    czero.nez a3, a3, a0
-; RV64ZICOND-NEXT:    czero.eqz s0, a2, a0
-; RV64ZICOND-NEXT:    or s0, s0, a3
+; RV64ZICOND-NEXT:    czero.eqz a2, a2, a0
+; RV64ZICOND-NEXT:    czero.nez s0, a3, a0
+; RV64ZICOND-NEXT:    or s0, s0, a2
 ; RV64ZICOND-NEXT:    beqz a1, .LBB58_2
 ; RV64ZICOND-NEXT:  # %bb.1:
 ; RV64ZICOND-NEXT:    mv a0, s0
diff --git a/llvm/test/CodeGen/RISCV/xaluo.ll b/llvm/test/CodeGen/RISCV/xaluo.ll
index 5d47ea4e9a6c..6786f440e713 100644
--- a/llvm/test/CodeGen/RISCV/xaluo.ll
+++ b/llvm/test/CodeGen/RISCV/xaluo.ll
@@ -664,7 +664,7 @@ define zeroext i1 @uaddo.i64(i64 %v1, i64 %v2, ptr %res) {
 ; RV32ZICOND-NEXT:    sltu a1, a3, a1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, a5
 ; RV32ZICOND-NEXT:    czero.nez a0, a0, a5
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    sw a2, 0(a4)
 ; RV32ZICOND-NEXT:    sw a3, 4(a4)
 ; RV32ZICOND-NEXT:    ret
@@ -1159,7 +1159,7 @@ define zeroext i1 @usubo.i64(i64 %v1, i64 %v2, ptr %res) {
 ; RV32ZICOND-NEXT:    sub a2, a0, a2
 ; RV32ZICOND-NEXT:    sltu a0, a0, a2
 ; RV32ZICOND-NEXT:    czero.nez a0, a0, a5
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    sw a2, 0(a4)
 ; RV32ZICOND-NEXT:    sw a3, 4(a4)
 ; RV32ZICOND-NEXT:    ret
@@ -2529,7 +2529,7 @@ define i64 @uaddo.select.i64(i64 %v1, i64 %v2) {
 ; RV32ZICOND-NEXT:    sltu a4, a4, a1
 ; RV32ZICOND-NEXT:    czero.eqz a4, a4, a6
 ; RV32ZICOND-NEXT:    czero.nez a5, a5, a6
-; RV32ZICOND-NEXT:    or a4, a4, a5
+; RV32ZICOND-NEXT:    or a4, a5, a4
 ; RV32ZICOND-NEXT:    czero.nez a2, a2, a4
 ; RV32ZICOND-NEXT:    czero.eqz a0, a0, a4
 ; RV32ZICOND-NEXT:    or a0, a0, a2
@@ -2604,7 +2604,7 @@ define i1 @uaddo.not.i64(i64 %v1, i64 %v2) {
 ; RV32ZICOND-NEXT:    sltu a1, a3, a1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, a2
 ; RV32ZICOND-NEXT:    czero.nez a0, a0, a2
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    xori a0, a0, 1
 ; RV32ZICOND-NEXT:    ret
 ;
@@ -3086,7 +3086,7 @@ define i64 @usubo.select.i64(i64 %v1, i64 %v2) {
 ; RV32ZICOND-NEXT:    sub a6, a0, a2
 ; RV32ZICOND-NEXT:    sltu a6, a0, a6
 ; RV32ZICOND-NEXT:    czero.nez a4, a6, a4
-; RV32ZICOND-NEXT:    or a4, a5, a4
+; RV32ZICOND-NEXT:    or a4, a4, a5
 ; RV32ZICOND-NEXT:    czero.nez a2, a2, a4
 ; RV32ZICOND-NEXT:    czero.eqz a0, a0, a4
 ; RV32ZICOND-NEXT:    or a0, a0, a2
@@ -3168,7 +3168,7 @@ define i1 @usubo.not.i64(i64 %v1, i64 %v2) {
 ; RV32ZICOND-NEXT:    sub a2, a0, a2
 ; RV32ZICOND-NEXT:    sltu a0, a0, a2
 ; RV32ZICOND-NEXT:    czero.nez a0, a0, a4
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    xori a0, a0, 1
 ; RV32ZICOND-NEXT:    ret
 ;
@@ -3234,7 +3234,6 @@ define i32 @smulo.select.i32(i32 signext %v1, i32 signext %v2) {
 ; RV32ZICOND-NEXT:    mul a3, a0, a1
 ; RV32ZICOND-NEXT:    srai a3, a3, 31
 ; RV32ZICOND-NEXT:    xor a2, a2, a3
-; RV32ZICOND-NEXT:    snez a2, a2
 ; RV32ZICOND-NEXT:    czero.nez a1, a1, a2
 ; RV32ZICOND-NEXT:    czero.eqz a0, a0, a2
 ; RV32ZICOND-NEXT:    or a0, a0, a1
@@ -3518,7 +3517,6 @@ define i64 @smulo.select.i64(i64 %v1, i64 %v2) {
 ; RV64ZICOND-NEXT:    mul a3, a0, a1
 ; RV64ZICOND-NEXT:    srai a3, a3, 63
 ; RV64ZICOND-NEXT:    xor a2, a2, a3
-; RV64ZICOND-NEXT:    snez a2, a2
 ; RV64ZICOND-NEXT:    czero.nez a1, a1, a2
 ; RV64ZICOND-NEXT:    czero.eqz a0, a0, a2
 ; RV64ZICOND-NEXT:    or a0, a0, a1
@@ -3772,7 +3770,6 @@ define i32 @umulo.select.i32(i32 signext %v1, i32 signext %v2) {
 ; RV32ZICOND-LABEL: umulo.select.i32:
 ; RV32ZICOND:       # %bb.0: # %entry
 ; RV32ZICOND-NEXT:    mulhu a2, a0, a1
-; RV32ZICOND-NEXT:    snez a2, a2
 ; RV32ZICOND-NEXT:    czero.nez a1, a1, a2
 ; RV32ZICOND-NEXT:    czero.eqz a0, a0, a2
 ; RV32ZICOND-NEXT:    or a0, a0, a1
@@ -3945,7 +3942,6 @@ define i64 @umulo.select.i64(i64 %v1, i64 %v2) {
 ; RV64ZICOND-LABEL: umulo.select.i64:
 ; RV64ZICOND:       # %bb.0: # %entry
 ; RV64ZICOND-NEXT:    mulhu a2, a0, a1
-; RV64ZICOND-NEXT:    snez a2, a2
 ; RV64ZICOND-NEXT:    czero.nez a1, a1, a2
 ; RV64ZICOND-NEXT:    czero.eqz a0, a0, a2
 ; RV64ZICOND-NEXT:    or a0, a0, a1
@@ -4394,7 +4390,7 @@ define zeroext i1 @uaddo.br.i64(i64 %v1, i64 %v2) {
 ; RV32ZICOND-NEXT:    sltu a1, a3, a1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, a2
 ; RV32ZICOND-NEXT:    czero.nez a0, a0, a2
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    beqz a0, .LBB55_2
 ; RV32ZICOND-NEXT:  # %bb.1: # %overflow
 ; RV32ZICOND-NEXT:    li a0, 0
@@ -4767,7 +4763,7 @@ define zeroext i1 @usubo.br.i64(i64 %v1, i64 %v2) {
 ; RV32ZICOND-NEXT:    sub a2, a0, a2
 ; RV32ZICOND-NEXT:    sltu a0, a0, a2
 ; RV32ZICOND-NEXT:    czero.nez a0, a0, a4
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    beqz a0, .LBB59_2
 ; RV32ZICOND-NEXT:  # %bb.1: # %overflow
 ; RV32ZICOND-NEXT:    li a0, 0
@@ -5596,10 +5592,10 @@ define zeroext i1 @umulo2.br.i64(i64 %v1) {
 ; RV32ZICOND-NEXT:    add a2, a1, a1
 ; RV32ZICOND-NEXT:    add a2, a2, a0
 ; RV32ZICOND-NEXT:    xor a3, a2, a1
-; RV32ZICOND-NEXT:    czero.nez a0, a0, a3
 ; RV32ZICOND-NEXT:    sltu a1, a2, a1
 ; RV32ZICOND-NEXT:    czero.eqz a1, a1, a3
-; RV32ZICOND-NEXT:    or a0, a1, a0
+; RV32ZICOND-NEXT:    czero.nez a0, a0, a3
+; RV32ZICOND-NEXT:    or a0, a0, a1
 ; RV32ZICOND-NEXT:    beqz a0, .LBB65_2
 ; RV32ZICOND-NEXT:  # %bb.1: # %overflow
 ; RV32ZICOND-NEXT:    li a0, 0
-- 
2.25.1

